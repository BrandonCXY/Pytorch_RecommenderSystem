{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.sparse as sp\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(test_num=100):\n",
    "    \"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
    "    train_data = pd.read_csv(\n",
    "        '/home/dm/Downloads/github_ncf/ml-1m.train.rating', \n",
    "        sep='\\t', header=None, names=['user', 'item'], \n",
    "        usecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n",
    "\n",
    "    user_num = train_data['user'].max() + 1\n",
    "    item_num = train_data['item'].max() + 1\n",
    "\n",
    "    train_data = train_data.values.tolist()\n",
    "\n",
    "    # load ratings as a dok matrix\n",
    "    train_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in train_data:\n",
    "        train_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "    test_data = []\n",
    "    with open('/home/dm/Downloads/github_ncf/ml-1m.test.negative', 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            test_data.append([u, eval(arr[0])[1]])\n",
    "            for i in arr[1:]:\n",
    "                test_data.append([u, int(i)])\n",
    "            line = fd.readline()\n",
    "    return train_data, test_data, user_num, item_num, train_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFData(data.Dataset):\n",
    "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
    "        super(NCFData, self).__init__()\n",
    "        \"\"\" Note that the labels are only useful when training, we thus \n",
    "            add them in the ng_sample() function.\n",
    "        \"\"\"\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0 for _ in range(len(features))]\n",
    "\n",
    "    def ng_sample(self):\n",
    "        # 在paper中提到，要算objective function的时候需要negative instances\n",
    "        # 一个postive instance对应4个negative instances(sampled from unobserved interactions)\n",
    "        # 因此只有train dataset需要negative sample，test dataset只是单单让他变成一个data.Dataset的实例\n",
    "        assert self.is_training, 'no need to sampling when testing'\n",
    "\n",
    "        self.features_ng = [] #例如，positive instance is (0,25)，\n",
    "                              #那么4个negative instances是(0,34)(0,9)(0,1778)(0,44) unobserved interactions\n",
    "        for x in self.features_ps:\n",
    "            u = x[0]\n",
    "            for t in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1 for _ in range(len(self.features_ps))]\n",
    "        labels_ng = [0 for _ in range(len(self.features_ng))]\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "\n",
    "    def __len__(self): # custom dataset class need both of _len_ and _getitem_ functions\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training \\\n",
    "                    else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training \\\n",
    "                    else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item ,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, factor_num, num_layers,\n",
    "                    dropout, model, GMF_model=None, MLP_model=None):\n",
    "        super(NCF, self).__init__()\n",
    "        \"\"\"\n",
    "        user_num: number of users;\n",
    "        item_num: number of items;\n",
    "        factor_num: number of predictive factors;\n",
    "        num_layers: the number of layers in MLP model;\n",
    "        dropout: dropout rate between fully connected layers;\n",
    "        model: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n",
    "        GMF_model: pre-trained GMF weights;\n",
    "        MLP_model: pre-trained MLP weights.\n",
    "        \"\"\"\n",
    "        self.dropout = dropout\n",
    "        self.model = model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.MLP_model = MLP_model\n",
    "\n",
    "        self.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
    "        self.embed_user_MLP = nn.Embedding(\n",
    "                user_num, factor_num * (2 ** (num_layers - 1))) #注意这里是num_layers -1\n",
    "        self.embed_item_MLP = nn.Embedding(\n",
    "                item_num, factor_num * (2 ** (num_layers - 1)))\n",
    "\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            # 注意这里是num_layers -i 因为输入是user embedding和 item embedding 的拼\n",
    "            # 所以输入的维度是(1,factor_num * 2 ** (num_layers)， 这里i从0开始，所以维度一样\n",
    "            input_size = factor_num * (2 ** (num_layers - i)) \n",
    "            MLP_modules.append(nn.Dropout(p=self.dropout))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        if self.model in ['MLP', 'GMF']:\n",
    "            predict_size = factor_num \n",
    "        else:\n",
    "            predict_size = factor_num * 2\n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    "\n",
    "        self._init_weight_()\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        \"\"\" We leave the weights initialization here. \"\"\"\n",
    "        if not self.model == 'NeuMF-pre':\n",
    "            nn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n",
    "\n",
    "            for m in self.MLP_layers:\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.kaiming_uniform_(self.predict_layer.weight, \n",
    "                                    a=1, nonlinearity='sigmoid')\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "        else:\n",
    "            # embedding layers\n",
    "            self.embed_user_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_user_GMF.weight)\n",
    "            self.embed_item_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_item_GMF.weight)\n",
    "            self.embed_user_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_user_MLP.weight)\n",
    "            self.embed_item_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_item_MLP.weight)\n",
    "\n",
    "            # mlp layers\n",
    "            for (m1, m2) in zip(\n",
    "                self.MLP_layers, self.MLP_model.MLP_layers):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "\n",
    "            # predict layers\n",
    "            predict_weight = torch.cat([\n",
    "                self.GMF_model.predict_layer.weight, \n",
    "                self.MLP_model.predict_layer.weight], dim=1)\n",
    "            precit_bias = self.GMF_model.predict_layer.bias + \\\n",
    "                        self.MLP_model.predict_layer.bias\n",
    "\n",
    "            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
    "            self.predict_layer.bias.data.copy_(0.5 * precit_bias)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # model = NeuMF-pre/end 既要算output_GMF也要output_MLP\n",
    "        if not self.model == 'MLP':\n",
    "            embed_user_GMF = self.embed_user_GMF(user)\n",
    "            embed_item_GMF = self.embed_item_GMF(item)\n",
    "            output_GMF = embed_user_GMF * embed_item_GMF #output dim is (1, factor_num)\n",
    "        if not self.model == 'GMF':\n",
    "            embed_user_MLP = self.embed_user_MLP(user) # (1 , factor_num * (2 ** (num_layers - 1)))\n",
    "            embed_item_MLP = self.embed_item_MLP(item)\n",
    "            interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1) # dim =-1 相当于 dim = 1, 横着拼\n",
    "            output_MLP = self.MLP_layers(interaction) # output dim is (1,factor_num)\n",
    "\n",
    "        if self.model == 'GMF':\n",
    "            concat = output_GMF\n",
    "        elif self.model == 'MLP':\n",
    "            concat = output_MLP\n",
    "        else:\n",
    "            concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "\n",
    "        prediction = self.predict_layer(concat)\n",
    "        return prediction.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k):\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.cuda()\n",
    "        item = item.cuda()\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        recommends = torch.take(\n",
    "                item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        gt_item = item[0].item()\n",
    "        HR.append(hit(gt_item, recommends))\n",
    "        NDCG.append(ndcg(gt_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def util_data():\n",
    "    \n",
    "    num_ng = 4\n",
    "    batch_size = 256\n",
    "    test_num_ng = 99\n",
    "\n",
    "\n",
    "    model_path = './models/'\n",
    "    GMF_model_path = model_path + 'GMF.pth'\n",
    "    MLP_model_path = model_path + 'MLP.pth'\n",
    "    NeuMF_model_path = model_path + 'NeuMF.pth'\n",
    "\n",
    "    ############################## PREPARE DATASET ##########################\n",
    "    train_data, test_data, user_num ,item_num, train_mat = load_all()\n",
    "\n",
    "    # Construct the train and test datasets\n",
    "    train_dataset = NCFData(train_data, item_num, train_mat, num_ng, True)\n",
    "\n",
    "    test_dataset = NCFData(test_data, item_num, train_mat, 0, False)\n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    test_loader = data.DataLoader(test_dataset,batch_size=test_num_ng+1, shuffle=False, num_workers=0)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_loader, test_loader, model_choose):\n",
    "    lr = 0.01\n",
    "    dropout = 0.0\n",
    "    epochs = 20\n",
    "    top_k  = 10\n",
    "    factor_num = 32\n",
    "    num_layers = 3\n",
    "    out = True   #save models or not\n",
    "    MODEL = model_choose  #'MLP', 'GMF', 'NeuMF-end', 'NeuMF-pre'\n",
    "\n",
    "    model_path = './models/'\n",
    "    GMF_model_path = model_path + 'GMF.pth'\n",
    "    MLP_model_path = model_path + 'MLP.pth'\n",
    "    NeuMF_model_path = model_path + 'NeuMF.pth'\n",
    "\n",
    "    if MODEL == 'NeuMF-pre':\n",
    "        #assert os.path.exists(GMF_model_path), 'lack of GMF model'\n",
    "        #assert os.path.exists(MLP_model_path), 'lack of MLP model'\n",
    "        GMF_model = torch.load(GMF_model_path)\n",
    "        MLP_model = torch.load(MLP_model_path)\n",
    "    else:\n",
    "        GMF_model = None\n",
    "        MLP_model = None\n",
    "\n",
    "    model = NCF(user_num, item_num,factor_num,num_layers, dropout, MODEL, GMF_model, MLP_model)\n",
    "    model.cuda()\n",
    "    loss_function = nn.BCEWithLogitsLoss() #Binary Cross Entropy\n",
    "\n",
    "    # choose the optimizer\n",
    "    if MODEL == 'NeuMF-pre':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    ########################### TRAINING #####################################\n",
    "    count, best_hr = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Enable dropout (if have).???????????\n",
    "        start_time = time.time()\n",
    "        train_loader.dataset.ng_sample() #??\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.cuda()\n",
    "            item = item.cuda()\n",
    "            label = label.float().cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # writer.add_scalar('data/loss', loss.item(), count)\n",
    "            count += 1\n",
    "\n",
    "        model.eval()\n",
    "        HR, NDCG = metrics(model, test_loader, top_k)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
    "                time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "        print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "        if HR > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "            if out:\n",
    "                if not os.path.exists(model_path):\n",
    "                    os.mkdir(model_path)\n",
    "                torch.save(model, \n",
    "                    '{}{}.pth'.format(model_path, MODEL))\n",
    "\n",
    "        print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(best_epoch, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = util_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapse of epoch 000 is: 00: 00: 52\n",
      "HR: 0.614\tNDCG: 0.351\n",
      "End. Best epoch 000: HR = 0.614, NDCG = 0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type NCF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/dm/anaconda3/envs/torch0/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapse of epoch 001 is: 00: 00: 52\n",
      "HR: 0.645\tNDCG: 0.375\n",
      "End. Best epoch 001: HR = 0.645, NDCG = 0.375\n",
      "The time elapse of epoch 002 is: 00: 00: 50\n",
      "HR: 0.658\tNDCG: 0.384\n",
      "End. Best epoch 002: HR = 0.658, NDCG = 0.384\n",
      "The time elapse of epoch 003 is: 00: 00: 53\n",
      "HR: 0.657\tNDCG: 0.383\n",
      "End. Best epoch 002: HR = 0.658, NDCG = 0.384\n",
      "The time elapse of epoch 004 is: 00: 00: 51\n",
      "HR: 0.659\tNDCG: 0.391\n",
      "End. Best epoch 004: HR = 0.659, NDCG = 0.391\n",
      "The time elapse of epoch 005 is: 00: 00: 52\n",
      "HR: 0.666\tNDCG: 0.393\n",
      "End. Best epoch 005: HR = 0.666, NDCG = 0.393\n",
      "The time elapse of epoch 006 is: 00: 00: 49\n",
      "HR: 0.679\tNDCG: 0.404\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 007 is: 00: 00: 52\n",
      "HR: 0.670\tNDCG: 0.397\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 008 is: 00: 00: 53\n",
      "HR: 0.678\tNDCG: 0.407\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 009 is: 00: 00: 51\n",
      "HR: 0.670\tNDCG: 0.397\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 010 is: 00: 00: 51\n",
      "HR: 0.666\tNDCG: 0.393\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 011 is: 00: 00: 52\n",
      "HR: 0.650\tNDCG: 0.384\n",
      "End. Best epoch 006: HR = 0.679, NDCG = 0.404\n",
      "The time elapse of epoch 012 is: 00: 00: 51\n",
      "HR: 0.688\tNDCG: 0.411\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 013 is: 00: 00: 50\n",
      "HR: 0.670\tNDCG: 0.398\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 014 is: 00: 00: 52\n",
      "HR: 0.680\tNDCG: 0.405\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 015 is: 00: 00: 52\n",
      "HR: 0.675\tNDCG: 0.400\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 016 is: 00: 00: 52\n",
      "HR: 0.673\tNDCG: 0.405\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 017 is: 00: 00: 53\n",
      "HR: 0.651\tNDCG: 0.381\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 018 is: 00: 00: 55\n",
      "HR: 0.644\tNDCG: 0.374\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n",
      "The time elapse of epoch 019 is: 00: 00: 53\n",
      "HR: 0.678\tNDCG: 0.406\n",
      "End. Best epoch 012: HR = 0.688, NDCG = 0.411\n"
     ]
    }
   ],
   "source": [
    "main(train_loader, test_loader, 'GMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapse of epoch 000 is: 00: 01: 12\n",
      "HR: 0.524\tNDCG: 0.285\n",
      "End. Best epoch 000: HR = 0.524, NDCG = 0.285\n",
      "The time elapse of epoch 001 is: 00: 01: 12\n",
      "HR: 0.581\tNDCG: 0.320\n",
      "End. Best epoch 001: HR = 0.581, NDCG = 0.320\n",
      "The time elapse of epoch 002 is: 00: 01: 11\n",
      "HR: 0.609\tNDCG: 0.345\n",
      "End. Best epoch 002: HR = 0.609, NDCG = 0.345\n",
      "The time elapse of epoch 003 is: 00: 01: 10\n",
      "HR: 0.631\tNDCG: 0.356\n",
      "End. Best epoch 003: HR = 0.631, NDCG = 0.356\n",
      "The time elapse of epoch 004 is: 00: 01: 13\n",
      "HR: 0.648\tNDCG: 0.371\n",
      "End. Best epoch 004: HR = 0.648, NDCG = 0.371\n",
      "The time elapse of epoch 005 is: 00: 01: 14\n",
      "HR: 0.639\tNDCG: 0.367\n",
      "End. Best epoch 004: HR = 0.648, NDCG = 0.371\n",
      "The time elapse of epoch 006 is: 00: 01: 14\n",
      "HR: 0.661\tNDCG: 0.379\n",
      "End. Best epoch 006: HR = 0.661, NDCG = 0.379\n",
      "The time elapse of epoch 007 is: 00: 01: 15\n",
      "HR: 0.656\tNDCG: 0.375\n",
      "End. Best epoch 006: HR = 0.661, NDCG = 0.379\n",
      "The time elapse of epoch 008 is: 00: 01: 14\n",
      "HR: 0.656\tNDCG: 0.383\n",
      "End. Best epoch 006: HR = 0.661, NDCG = 0.379\n",
      "The time elapse of epoch 009 is: 00: 01: 10\n",
      "HR: 0.664\tNDCG: 0.371\n",
      "End. Best epoch 009: HR = 0.664, NDCG = 0.371\n",
      "The time elapse of epoch 010 is: 00: 01: 13\n",
      "HR: 0.664\tNDCG: 0.372\n",
      "End. Best epoch 009: HR = 0.664, NDCG = 0.371\n",
      "The time elapse of epoch 011 is: 00: 01: 12\n",
      "HR: 0.654\tNDCG: 0.362\n",
      "End. Best epoch 009: HR = 0.664, NDCG = 0.371\n",
      "The time elapse of epoch 012 is: 00: 01: 11\n",
      "HR: 0.667\tNDCG: 0.352\n",
      "End. Best epoch 012: HR = 0.667, NDCG = 0.352\n",
      "The time elapse of epoch 013 is: 00: 01: 12\n",
      "HR: 0.651\tNDCG: 0.361\n",
      "End. Best epoch 012: HR = 0.667, NDCG = 0.352\n",
      "The time elapse of epoch 014 is: 00: 01: 13\n",
      "HR: 0.655\tNDCG: 0.339\n",
      "End. Best epoch 012: HR = 0.667, NDCG = 0.352\n",
      "The time elapse of epoch 015 is: 00: 01: 10\n",
      "HR: 0.687\tNDCG: 0.334\n",
      "End. Best epoch 015: HR = 0.687, NDCG = 0.334\n",
      "The time elapse of epoch 016 is: 00: 01: 13\n",
      "HR: 0.645\tNDCG: 0.341\n",
      "End. Best epoch 015: HR = 0.687, NDCG = 0.334\n",
      "The time elapse of epoch 017 is: 00: 01: 11\n",
      "HR: 0.723\tNDCG: 0.305\n",
      "End. Best epoch 017: HR = 0.723, NDCG = 0.305\n",
      "The time elapse of epoch 018 is: 00: 01: 12\n",
      "HR: 0.804\tNDCG: 0.294\n",
      "End. Best epoch 018: HR = 0.804, NDCG = 0.294\n",
      "The time elapse of epoch 019 is: 00: 01: 12\n",
      "HR: 0.738\tNDCG: 0.328\n",
      "End. Best epoch 018: HR = 0.804, NDCG = 0.294\n"
     ]
    }
   ],
   "source": [
    "main(train_loader, test_loader, 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“torch0”",
   "language": "python",
   "name": "torch0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
